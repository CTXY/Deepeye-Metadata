#!/usr/bin/env python3
"""
æ–°ç‰ˆæŸ¥è¯¢å·®å¼‚åˆ†æå™¨æµ‹è¯•è„šæœ¬

æµ‹è¯•æ”¹è¿›åçš„3ä¸ªæ ¸å¿ƒå‡½æ•°å’Œæ–°æŠ¥å‘Šç³»ç»Ÿã€‚
ä½¿ç”¨Card Gamesæ•°æ®åº“éªŒè¯"Query 1 vs Query 2"çš„åˆ†æèƒ½åŠ›ã€‚

Author: Generated for DeepEye-SQL-Metadata project
Date: 2025-12
"""

import os
import sys
from pathlib import Path

# æ·»åŠ è·¯å¾„
script_dir = Path(__file__).parent
sys.path.append(str(script_dir))

from llm_query_difference_interface import (
    check_field_uniqueness,
    analyze_query_difference, 
    generate_query_strategy_report,
    get_database_table_info,
    suggest_query_analysis_targets,
    complete_query_difference_workflow
)


def test_new_analyzer_system():
    """
    æµ‹è¯•æ–°ç‰ˆåˆ†æå™¨ç³»ç»Ÿ
    
    é‡ç‚¹éªŒè¯ç”¨æˆ·å…³å¿ƒçš„æ ¸å¿ƒåœºæ™¯ï¼š
    1. SELECT * FROM cards WHERE setCode = 'OGW'
    2. SELECT * FROM cards JOIN set_translations ON ... WHERE setCode = 'OGW'
    """
    
    # Card Gamesæ•°æ®åº“è·¯å¾„
    db_path = "/home/yangchenyu/DeepEye-SQL-Metadata/dataset/bird/databases/dev_databases/card_games/card_games.sqlite"
    
    if not os.path.exists(db_path):
        print(f"âŒ æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
        return
    
    print("ğŸš€ æµ‹è¯•æ–°ç‰ˆæŸ¥è¯¢å·®å¼‚åˆ†æå™¨")
    print("=" * 60)
    
    # æµ‹è¯•1: æ•°æ®åº“åŸºæœ¬ä¿¡æ¯
    print("\nğŸ“‹ æµ‹è¯•1: è·å–æ•°æ®åº“åŸºæœ¬ä¿¡æ¯")
    db_info = get_database_table_info(db_path)
    if "error" in db_info:
        print(f"âŒ å¤±è´¥: {db_info['error']}")
        return
        
    print(f"âœ… å‘ç° {db_info['total_tables']} ä¸ªè¡¨:")
    for table in db_info['tables']:
        print(f"   - {table['name']}")
    
    # æµ‹è¯•2: å­—æ®µå”¯ä¸€æ€§æ£€æŸ¥
    print("\nğŸ” æµ‹è¯•2: å­—æ®µå”¯ä¸€æ€§æ£€æŸ¥")
    
    # æ£€æŸ¥ cards.setCode æ˜¯å¦é€‚åˆä½œä¸ºJOIN key
    print("\næ£€æŸ¥ cards.setCode:")
    cards_uniqueness = check_field_uniqueness(db_path, "cards", "setCode")
    if "error" in cards_uniqueness:
        print(f"âŒ å¤±è´¥: {cards_uniqueness['error']}")
    else:
        print(f"  âœ… æ˜¯å¦é€‚åˆä½œä¸ºJOIN key: {'æ˜¯' if cards_uniqueness['can_be_join_key'] else 'å¦'}")
        print(f"  âœ… æ˜¯å¦å®Œå…¨å”¯ä¸€: {'æ˜¯' if cards_uniqueness['is_unique'] else 'å¦'}")
        print(f"  âœ… é‡å¤ç‡: {cards_uniqueness['duplication_rate']*100:.2f}%")
        print(f"  âœ… å”¯ä¸€å€¼æ•°é‡: {cards_uniqueness['unique_values']}")
    
    # æ£€æŸ¥ set_translations.setCode
    print("\næ£€æŸ¥ set_translations.setCode:")
    translations_uniqueness = check_field_uniqueness(db_path, "set_translations", "setCode")
    if "error" in translations_uniqueness:
        print(f"âŒ å¤±è´¥: {translations_uniqueness['error']}")
    else:
        print(f"  âœ… æ˜¯å¦é€‚åˆä½œä¸ºJOIN key: {'æ˜¯' if translations_uniqueness['can_be_join_key'] else 'å¦'}")
        print(f"  âœ… æ˜¯å¦å®Œå…¨å”¯ä¸€: {'æ˜¯' if translations_uniqueness['is_unique'] else 'å¦'}")
        print(f"  âœ… é‡å¤ç‡: {translations_uniqueness['duplication_rate']*100:.2f}%")
        print(f"  âœ… å”¯ä¸€å€¼æ•°é‡: {translations_uniqueness['unique_values']}")
    
    # æµ‹è¯•3: æ ¸å¿ƒæŸ¥è¯¢å·®å¼‚åˆ†æ  
    print("\nğŸ”¥ æµ‹è¯•3: æŸ¥è¯¢å·®å¼‚åˆ†æ (cards.setCode vs set_translations.setCode)")
    
    analysis_result = analyze_query_difference(
        db_path,
        "cards", "setCode",           # Query 1: SELECT ... FROM cards WHERE setCode = 'OGW'
        "set_translations", "setCode"  # Query 2: SELECT ... FROM cards JOIN set_translations WHERE setCode = 'OGW'
    )
    
    if "error" in analysis_result:
        print(f"âŒ åˆ†æå¤±è´¥: {analysis_result['error']}")
        return
    
    print("âœ… æŸ¥è¯¢å·®å¼‚åˆ†æå®Œæˆï¼å…³é”®å‘ç°:")
    
    # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
    join_mapping = analysis_result['join_mapping']
    print(f"  ğŸ” æœ€å¤§æ‰‡å‡º: {join_mapping['max_fan_out']}")
    print(f"  ğŸ“Š åŒ¹é…ç‡: {join_mapping['match_ratio']*100:.1f}%")
    print(f"  ğŸ“ å…³ç³»ç±»å‹: {join_mapping['mapping_type']}")
    print(f"  âš ï¸  è†¨èƒ€é£é™©: {join_mapping['fan_out_risk']}")
    print(f"  âš ï¸  è¿‡æ»¤é£é™©: {join_mapping['filtering_risk']}")
    print(f"  ğŸ¯ é¢„è®¡JOINç»“æœè¡Œæ•°: {join_mapping['estimated_result_rows']}")
    
    # æ•°æ®å®Œæ•´æ€§
    completeness = analysis_result['data_completeness']
    print(f"  ğŸ“‹ æ•°æ®å®Œæ•´æ€§: {completeness['completeness_ratio']*100:.1f}%")
    print(f"  ğŸ”¤ ç¼ºå¤±å€¼æ•°é‡: {completeness['missing_in_b_count']}")
    
    # æµ‹è¯•4: ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š
    print("\nğŸ“Š æµ‹è¯•4: ç”ŸæˆæŸ¥è¯¢ç­–ç•¥æŠ¥å‘Š")
    
    report_result = generate_query_strategy_report(
        analysis_result,
        main_table_name="å¡ç‰Œè¡¨(cards)", 
        join_table_name="ç³»åˆ—ç¿»è¯‘è¡¨(set_translations)",
        save_to_temp=True,
        output_format="all"
    )
    
    if "error" in report_result:
        print(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {report_result['error']}")
        return
    
    print("âœ… ç»“æ„åŒ–æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
    
    # æ˜¾ç¤ºæ ¸å¿ƒè¯Šæ–­ç»“æœ
    diagnosis = report_result['report']['executive_diagnosis']
    print(f"  ğŸ† æœ€ç»ˆç»“è®º: {diagnosis['final_conclusion']}")
    print(f"  ğŸ’¡ å¿«é€Ÿæ€»ç»“: {diagnosis['quick_summary']}")
    
    # æ˜¾ç¤ºå»ºè®®
    advice = report_result['report']['actionable_advice']
    if advice['priority_recommendations']:
        rec = advice['priority_recommendations'][0]
        print(f"  ğŸ¯ ä¸»è¦å»ºè®®: {rec['strategy']}")
        print(f"  ğŸ“ åŸå› : {rec['reason']}")
    
    # æ˜¾ç¤ºä¿å­˜çš„æ–‡ä»¶
    if 'saved_files' in report_result:
        files = report_result['saved_files']
        print(f"\nğŸ“ æŠ¥å‘Šå·²ä¿å­˜åˆ°tempæ–‡ä»¶å¤¹:")
        print(f"  - JSONæ ¼å¼: {os.path.basename(files.get('json', ''))}")
        print(f"  - Markdownæ ¼å¼: {os.path.basename(files.get('markdown', ''))}")
        print(f"  - æ–‡æœ¬æ‘˜è¦: {os.path.basename(files.get('text_summary', ''))}")
    
    # æµ‹è¯•5: å®Œæ•´å·¥ä½œæµ
    print("\nğŸ¬ æµ‹è¯•5: å®Œæ•´å·¥ä½œæµ")
    
    workflow_result = complete_query_difference_workflow(
        db_path,
        "cards", "setCode",
        "set_translations", "setCode",
        "å¡ç‰Œè¡¨", "ç³»åˆ—ç¿»è¯‘è¡¨",
        save_report=True
    )
    
    if "error" in workflow_result:
        print(f"âŒ å·¥ä½œæµå¤±è´¥: {workflow_result['error']}")
    else:
        print("âœ… å®Œæ•´å·¥ä½œæµæ‰§è¡ŒæˆåŠŸï¼")
        summary = workflow_result['summary'] 
        print(f"  ğŸ¯ åˆ†æå¯¹è±¡: {summary['main_field']} vs {summary['join_field']}")
        print(f"  ğŸ† ç»“è®º: {summary['conclusion']}")
        print(f"  âš ï¸  å…³é”®é£é™©: è†¨èƒ€({summary['key_risks']['fan_out']}) / è¿‡æ»¤({summary['key_risks']['filtering']})")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æµ‹è¯•å®Œæˆï¼æ–°ç‰ˆåˆ†æå™¨è¿è¡Œæ­£å¸¸")
    

if __name__ == "__main__":
    test_new_analyzer_system()
