# Data types and models for Memory subsystem

import logging
from enum import Enum
from pydantic import BaseModel
from typing import Optional, Dict, Any, List, Tuple
from datetime import datetime

logger = logging.getLogger(__name__)

class MemoryType(Enum):
    """Memory type enumeration"""
    EPISODIC = "episodic"      # Historical interaction records
    SEMANTIC = "semantic"      # Schema and domain knowledge
    GUIDANCE = "guidance"      # Operational guidance from historical error patterns

class MemoryQuery(BaseModel):
    """Memory query request"""
    memory_type: MemoryType
    query_content: str                           # Query content
    context: Optional[Dict[str, Any]] = None     # Additional context                 # Result limit per term
    similarity_threshold: Optional[float] = None # Minimum similarity threshold for results
    generated_sql: Optional[str] = None            # Generated SQL
    intent_analysis: Optional[Any] = None        # Pre-analyzed intent analysis (IntentAnalysis from caf.utils.query_analyzer) to avoid redundant parsing

class MemoryItem(BaseModel):
    """Single memory item in response"""
    content: Dict[str, Any]    # Memory content
    score: float               # Relevance score
    tags: Dict[str, Any]       # Internal tags for memory type, e.g. semantic memory and table-level metadata


class MemoryResponse(BaseModel):
    """Memory query response"""
    items: List[MemoryItem]    # Retrieved memory items
    query_time_ms: int         # Query time in milliseconds


class SchemaMetadataResponse(BaseModel):
    """
    Response for get_schema_metadata() - metadata for already-selected schema
    
    This is used when reasoning module already has schema linking results
    and only needs to fetch metadata (descriptions, joins, etc.)
    """
    tables: Dict[str, Dict[str, Any]]      # table_name -> table metadata
    columns: Dict[str, Dict[str, Any]]     # "table.column" -> column metadata
    joins: List[Dict[str, Any]]            # list of join relationships between tables
    query_time_ms: int                     # Query time in milliseconds


class SQLInsightsResponse(BaseModel):
    """
    Response for get_sql_insights() - insights based on candidate SQLs
    
    (预留接口 - Not yet implemented)
    Future insights may include:
    - Similar SQL patterns from episodic memory
    - Ambiguous column pair warnings
    - Common error patterns
    - Suggested optimizations
    """
    insights: List[Dict[str, Any]]         # List of insights
    candidate_count: int                   # Number of candidate SQLs analyzed
    query_time_ms: int                     # Query time in milliseconds

class SQLExecutionResult(BaseModel):
    """SQL execution result structure"""
    execution_success: bool                        # Whether SQL executed successfully
    results: Optional[List[Dict[str, Any]]] = None # Query results (list of row dictionaries)
    error_message: Optional[str] = None            # Error message if execution failed
    row_count: Optional[int] = None                # Number of rows returned
    execution_time_ms: Optional[float] = None      # Execution time in milliseconds

class UserFeedback(BaseModel):
    """User feedback structure"""
    label: bool                                    # True if SQL is correct, False otherwise
    error_types: Optional[List[Dict[str, str]]] = None  # Error types if label is False
    feedback_text: Optional[str] = None            # Optional text feedback from user
    timestamp: Optional[str] = None

class InteractionRound(BaseModel):
    """Single round of interaction within a session"""
    round_id: int
    generated_sql: Optional[str] = None
    execution_result: Optional[SQLExecutionResult] = None
    llm_interactions: Optional[List[Dict[str, Any]]] = None
    user_feedback: Optional[UserFeedback] = None
    timestamp: str
    metadata: Optional[Dict[str, Any]] = None
    
    def __init__(self, **data):
        if 'timestamp' not in data:
            data['timestamp'] = datetime.utcnow().isoformat()
        
        # Handle dict to SQLExecutionResult conversion
        if 'execution_result' in data and data['execution_result'] is not None:
            if isinstance(data['execution_result'], dict):
                data['execution_result'] = SQLExecutionResult(**data['execution_result'])
        
        # Handle dict to UserFeedback conversion
        if 'user_feedback' in data and data['user_feedback'] is not None:
            if isinstance(data['user_feedback'], dict):
                data['user_feedback'] = UserFeedback(**data['user_feedback'])
        
        super().__init__(**data)

class EpisodicRecord(BaseModel):
    """Flattened episodic memory record - each round is stored as a separate record"""
    session_id: Optional[str] = None  # Will be generated by store if not provided
    database_id: Optional[str] = None
    user_query: str
    context: Optional[str] = None  # Evidence or context provided by user
    round_id: int
    generated_sql: Optional[str] = None
    execution_result: Optional[SQLExecutionResult] = None
    label: Optional[bool] = None  # True if SQL is correct, False otherwise
    error_types: Optional[List[Dict[str, str]]] = None  # Error types if label is False
    feedback_text: Optional[str] = None  # Optional text feedback from user
    source_model: Optional[str] = None  # Source model information
    timestamp: str
    metadata: Optional[Dict[str, Any]] = None
    
    def __init__(self, **data):
        if 'timestamp' not in data:
            data['timestamp'] = datetime.utcnow().isoformat()
        
        # Handle backward compatibility: convert from old format
        self._convert_from_old_format(data)
        
        # Handle execution_result conversion
        if 'execution_result' in data and data['execution_result'] is not None:
            if isinstance(data['execution_result'], dict):
                data['execution_result'] = SQLExecutionResult(**data['execution_result'])
        
        super().__init__(**data)
    
    def _convert_from_old_format(self, data: Dict[str, Any]) -> None:
        """Convert from old format with rounds to flattened format"""
        # If we have rounds, extract the first round's data
        if 'rounds' in data and data['rounds']:
            rounds = data['rounds']
            if isinstance(rounds, list) and len(rounds) > 0:
                first_round = rounds[0] if isinstance(rounds[0], dict) else rounds[0].dict()
                
                # Extract round data
                if 'round_id' not in data:
                    data['round_id'] = first_round.get('round_id', 1)
                if 'generated_sql' not in data:
                    data['generated_sql'] = first_round.get('generated_sql')
                if 'execution_result' not in data:
                    data['execution_result'] = first_round.get('execution_result')
                
                # Extract user feedback
                user_feedback = first_round.get('user_feedback')
                if user_feedback:
                    if isinstance(user_feedback, dict):
                        if 'label' not in data:
                            data['label'] = user_feedback.get('label')
                        if 'error_types' not in data:
                            data['error_types'] = user_feedback.get('error_types')
                        if 'feedback_text' not in data:
                            data['feedback_text'] = user_feedback.get('feedback_text')
                    elif hasattr(user_feedback, 'label'):
                        if 'label' not in data:
                            data['label'] = user_feedback.label
                        if 'error_types' not in data:
                            data['error_types'] = user_feedback.error_types
                        if 'feedback_text' not in data:
                            data['feedback_text'] = user_feedback.feedback_text
                
                # Extract metadata
                if 'source_model' not in data and first_round.get('metadata'):
                    metadata = first_round.get('metadata', {})
                    data['source_model'] = metadata.get('source_model')
            
            # Remove rounds from data
            data.pop('rounds', None)
        
        # Handle old single-interaction format
        if 'generated_sql' in data and 'round_id' not in data:
            data['round_id'] = 1
        
        # Handle execution_success field (old field name)
        if 'execution_success' in data and 'execution_result' not in data:
            execution_success = data.pop('execution_success')
            data['execution_result'] = {'execution_success': execution_success}
        elif 'execution_success' in data and isinstance(data.get('execution_result'), dict):
            data['execution_result']['execution_success'] = data.pop('execution_success')
        
        # Handle user_feedback at top level (old format)
        if 'user_feedback' in data and isinstance(data['user_feedback'], dict):
            user_feedback = data.pop('user_feedback')
            if 'label' not in data:
                data['label'] = user_feedback.get('label')
            if 'error_types' not in data:
                data['error_types'] = user_feedback.get('error_types')
            if 'feedback_text' not in data:
                data['feedback_text'] = user_feedback.get('feedback_text')
        elif 'user_feedback' in data and hasattr(data['user_feedback'], 'label'):
            user_feedback = data.pop('user_feedback')
            if 'label' not in data:
                data['label'] = user_feedback.label
            if 'error_types' not in data:
                data['error_types'] = user_feedback.error_types
            if 'feedback_text' not in data:
                data['feedback_text'] = user_feedback.feedback_text

# =============================================================================
# Semantic Memory Data Models
# =============================================================================

class DatabaseMetadata(BaseModel):
    """Database-level metadata"""
    database_id: str
    description: Optional[str] = None
    domain: Optional[str] = None
    total_tables: Optional[int] = None
    total_rows: Optional[int] = None

class TableMetadata(BaseModel):
    """Table-level metadata"""
    database_id: str
    table_name: str
    description: Optional[str] = None
    row_count: Optional[int] = None
    column_count: Optional[int] = None
    primary_keys: Optional[List[str]] = None
    foreign_keys: Optional[List[Dict[str, Any]]] = None
    sample_data: Optional[Dict[str, List]] = None

    co_occurring_tables: Optional[Dict[str, int]] = None  # table_name -> frequency
    
    # === Deep semantic metadata (for NL2SQL optimization) ===
    table_role: Optional[str] = None  # "Fact" | "Dimension" | "Bridge" | "Lookup"
    row_definition: Optional[str] = None  # "Each row represents..." - describes what each row means

    
    # === Topology features (computed from FK relationships) ===
    fk_in_degree: Optional[int] = None  # How many tables reference this table
    fk_out_degree: Optional[int] = None  # How many tables this table references


class ColumnMetadata(BaseModel):
    """Column-level metadata with detailed profiling statistics"""
    database_id: str
    table_name: str
    column_name: str
    whole_column_name: Optional[str] = None
    
    description: Optional[str] = None
    data_type: Optional[str] = None  # The underlying storage type of the column in the database (e.g., TEXT, INTEGER, REAL). 
    data_format: Optional[str] = None   # The specific semantic pattern or convention of the data within the column (e.g., 'YYYY-MM-DD', 'Email', 'JSON').
    semantic_type: Optional[str] = None  # Inferred type by profiler: 'Categorical', 'Numerical', 'Identifier', 'Datetime', 'Free_Text', 'Unknown'

    is_nullable: Optional[bool] = None
    is_primary_key: Optional[bool] = None
    

    encoding_mapping: Optional[Dict[str, str]] = None

    semantic_tags: Optional[List[Dict[str, Any]]] = None # e.g., [{'type': 'BUSINESS_RULE', 'content': 'Status changes to 99 for archived records.', 'source': 'manual'}]

    # Detailed profiling statistics
    null_count: Optional[int] = None
    distinct_count: Optional[int] = None
    # distinct_values: Removed - use top_k_values instead for value examples
    min_value: Optional[Any] = None
    max_value: Optional[Any] = None
    pattern_description: Optional[str] = None
    
    # Shape features (length statistics for string-like columns)
    min_length: Optional[int] = None
    max_length: Optional[int] = None
    avg_length: Optional[float] = None
    
    # Fixity features: stable prefix/suffix detected from sample values
    fixed_prefix: Optional[str] = None
    fixed_suffix: Optional[str] = None
    
    # Top-K values and their frequencies
    top_k_values: Optional[Dict[Any, int]] = None
    
    
    # Natural language descriptions for LLM consumption
    short_description: Optional[str] = None  # Concise semantic summary for Schema Linking
    long_description: Optional[str] = None   # Detailed description with statistics for SQL generation
    
    # Semantic similarity and advanced relationship discovery
    semantically_similar_columns: Optional[List[Dict[str, Any]]] = None
    minhash_sketch: Optional[bytes] = None

    
class RelationshipMetadata(BaseModel):
    """Relationship metadata between tables with support for complex joins"""
    database_id: str
    relationship_type: str  # 'foreign_key', 'one_to_many', 'multi_field_join', etc.
    source_table: str
    target_table: str
    
    # Support for multi-field joins (replacing single column fields)
    source_columns: List[str]  # List of source columns for multi-field joins
    target_columns: List[str]  # List of target columns for multi-field joins
    
    source: Optional[str] = 'ddl_extract' # 'ddl_extract', 'manual', 'historical', 'llm_analysis'
    
    # Relationship analysis fields
    cardinality: Optional[str] = None  # "1:1", "1:N", "N:1", "N:M", "Lookup" - computed from actual JOIN queries
    business_meaning: Optional[str] = None  # Business relationship description (e.g., "Identifies (1:1)", "Belongs to (N:1)", "Measures (1:N)", "References (Lookup)")
    

class TermDefinition(BaseModel):
    """Domain-specific term definitions
    
    Note:
        - `definition` can be a single string or a list of strings.
          Internally in the semantic store we treat it as a list and
          append new definitions instead of overwriting existing ones.
    """
    database_id: str
    term_name: str
    definition: Any  # str or List[str]
    formula: Optional[str] = None
    example_usage: Optional[str] = None
    context: Optional[str] = None


class GoldenPair(BaseModel):
    """Golden (NLQ, SQL) 对"""
    natural_language_query: str                     # 自然语言查询
    sql_query: str                                  # SQL查询
    database_id: str                                # 数据库ID
    quality_score: Optional[float] = None           # 质量分数
    source: Optional[str] = None                    # 数据来源
    evidence: Optional[str] = None                  # Evidence 或上下文信息（存储在 EpisodicRecord.context 中）
    timestamp: str                                  # 时间戳
    
    def __init__(self, **data):
        if 'timestamp' not in data:
            data['timestamp'] = datetime.utcnow().isoformat()
        super().__init__(**data)


# =============================================================================
# Ambiguous Pairs - for schema-level ambiguous/similar fields (Pairwise)
# =============================================================================

class DBElementRef(BaseModel):
    """
    Lightweight reference to a database element (currently column-level).
    
    We intentionally only store table/column here; database_id is stored
    at the pair/cluster level to avoid duplication.
    """
    table_name: str
    column_name: str


class CollisionInfo(BaseModel):
    """Information about a pseudo-query collision"""
    trigger_query: str  # The generated query that triggered the collision
    source_column_id: str  # The column that generated this query (table.column format)
    distractor_column_id: str  # The column that was incorrectly retrieved (table.column format)
    collision_score: float  # The retrieval score for the distractor
    target_score: float  # The retrieval score for the target column
    query_type: str  # "exact_match", "value_based", or "concept_based"
    collision_type: str  # "semantic_ambiguity" or "value_overlap_ambiguity"


# =============================================================================
# Data Content Profile - 数据内容维度分析
# =============================================================================

class DataContentProfile(BaseModel):
    """
    数据内容维度的分析结果.
    
    维度一：Data Content Perspective
    - 集合拓扑分析 (Set Topology)
    - 逻辑约束检测 (Logical Constraints)
    - 结果敏感性/反事实分析 (Result Sensitivity)
    """
    
    # 1. 集合拓扑分析 (Set Topology Analysis)
    set_relationship: Optional[str] = None  # "A_subset_of_B", "B_subset_of_A", "mutually_exclusive", "overlapping", "unknown"
    containment_a_in_b: Optional[float] = None  # |A∩B| / |A|
    containment_b_in_a: Optional[float] = None  # |A∩B| / |B|
    jaccard_similarity: Optional[float] = None  # |A∩B| / |A∪B|
    
    # 2. 逻辑约束检测 (Logical Constraints Detection)
    constraint_rule: Optional[str] = None  # e.g., "A <= B", "A > B", "A == B", None
    constraint_violation_rate: Optional[float] = None  # 违反约束的比例 (0.0 = strict constraint)
    constraint_sample_size: Optional[int] = None  # 用于检测约束的样本数量
    
    # 3. 结果敏感性/反事实分析 (Result Sensitivity / Counterfactual Analysis)
    sensitivity_type: Optional[str] = None  # "low_sensitivity" (synonyms/safe to swap), "high_sensitivity" (distinct/dangerous), "context_dependent"
    avg_result_overlap: Optional[float] = None  # 平均 Jaccard similarity of result sets when using same value
    sampled_value_count: Optional[int] = None  # 采样了多少个共同 value
    
    # 示例 cases (用于 LLM 理解和调试)
    example_cases: Optional[List[Dict[str, Any]]] = None  # [{value, rows_a_count, rows_b_count, overlap_jaccard}, ...]


class SemanticIntentProfile(BaseModel):
    """
    语义意图维度的分析结果 (LLM-based).
    
    维度二：Semantic Intent Perspective
    - 实体/属性归属 (Entity Alignment)
    - 判别性场景生成 (Discriminative Scenario Generation)
    """
    
    # 1. 实体/属性归属 (Entity Alignment)
    entity_alignment: Optional[str] = None  # LLM 生成的实体归属总结描述
    column_a_entity: Optional[str] = None  # e.g., "Supplier entity"
    column_b_entity: Optional[str] = None  # e.g., "Product entity"
    
    # 2. 判别性场景生成 (Discriminative Scenario Generation)
    semantic_nuance: Optional[str] = None  # LLM 总结的语义差异核心描述
    scenario_a: Optional[str] = None  # 什么情况下必须用 column_a (Question example)
    scenario_b: Optional[str] = None  # 什么情况下必须用 column_b (Question example)
    discriminative_logic: Optional[str] = None  # 区分逻辑：为什么 A 用于场景 A，B 用于场景 B
    
    # Trigger keywords mapping (从 scenarios 中提取或 LLM 生成)
    trigger_keywords_a: Optional[List[str]] = None  # e.g., ["bought", "placed", "created", "sales"]
    trigger_keywords_b: Optional[List[str]] = None  # e.g., ["delivered", "sent", "shipped", "logistics"]


class DiffProfile(BaseModel):
    """
    完整的 Diff Profile：综合数据内容和语义意图两个维度的分析结果.
    
    用于 Ambiguity Discriminator Matrix，帮助 Agent 在 SQL 生成时正确选择字段。
    """
    data_content_profile: Optional[DataContentProfile] = None
    semantic_intent_profile: Optional[SemanticIntentProfile] = None
    
    # Guidance rule (综合两个维度生成的最终建议，用于 Agent prompt)
    guidance_rule: Optional[str] = None
    
    # Metadata
    analysis_timestamp: str
    analysis_version: Optional[str] = None  # e.g., "v1.0"
    
    def __init__(self, **data):
        if 'analysis_timestamp' not in data:
            data['analysis_timestamp'] = datetime.utcnow().isoformat()
        super().__init__(**data)


# =============================================================================
# Ambiguous Pair - 模糊字段对
# =============================================================================

class AmbiguousPair(BaseModel):
    """
    一对模糊字段 (Ambiguous Column Pair).
    
    存储两个语义相似/值重叠的字段，以及它们的差异分析结果 (Diff Profile)。
    用于 Text-to-SQL 系统中的字段消歧 (Column Disambiguation)。
    
    Design:
    - Pairwise storage (not group/cluster) for precise disambiguation
    - Each pair has unique discovery signals (pseudo-query collision, value overlap)
    - Diff Profile provides actionable guidance for column selection
    """
    pair_id: str  # Format: "{database_id}_{table_a}.{col_a}__{table_b}.{col_b}"
    database_id: str
    
    # Two columns in this ambiguous pair
    column_a: DBElementRef
    column_b: DBElementRef
    
    # Discovery methods and signals (from miners)
    discovery_methods: List[str] = []  # e.g., ["pseudo_query_collision", "value_overlap"]
    
    # Mining signals
    semantic_collision_score: Optional[float] = None  # From pseudo-query collision miner
    value_jaccard: Optional[float] = None  # From value overlap miner
    
    # Collision details (if discovered by pseudo-query collision)
    collision_details: Optional[List[CollisionInfo]] = None
    
    # Diff Profile (NEW: deep analysis results)
    diff_profile: Optional[DiffProfile] = None
    
    # Metadata
    discovered_at: str  # Timestamp when this pair was discovered
    last_analyzed_at: Optional[str] = None  # Timestamp when diff_profile was last updated
    
    def __init__(self, **data):
        if 'discovered_at' not in data:
            data['discovered_at'] = datetime.utcnow().isoformat()
        super().__init__(**data)
    
    def get_sorted_pair_key(self) -> Tuple[Tuple[str, str], Tuple[str, str]]:
        """
        Get a canonical sorted pair key for deduplication.
        
        Returns:
            Tuple of ((table_a, col_a), (table_b, col_b)) in sorted order
        """
        key_a = (self.column_a.table_name, self.column_a.column_name)
        key_b = (self.column_b.table_name, self.column_b.column_name)
        return tuple(sorted([key_a, key_b]))


# =============================================================================
# Legacy: Similarity Clusters (DEPRECATED - replaced by AmbiguousPair)
# =============================================================================

class SimilarityCluster(BaseModel):
    """
    DEPRECATED: Use AmbiguousPair instead.
    
    Similarity cluster of columns within a single database.
    Kept for backward compatibility with old code.
    """
    cluster_id: str
    database_id: str

    elements: List[DBElementRef]
    methods: List[str] = []

    # Semantic similarity statistics within the cluster
    semantic_score_min: Optional[float] = None
    semantic_score_max: Optional[float] = None
    semantic_score_avg: Optional[float] = None

    # Value-level Jaccard similarity statistics (if available)
    value_jaccard_min: Optional[float] = None
    value_jaccard_max: Optional[float] = None

    # Overlap coefficient statistics (|A∩B| / min(|A|,|B|)) if computed
    value_overlap_min: Optional[float] = None
    value_overlap_max: Optional[float] = None

    # Pseudo-query collision information (for pseudo_query_collision method)
    collision_info: Optional[List[CollisionInfo]] = None

# =============================================================================
# Version Management Data Models
# =============================================================================

class FieldVersion(BaseModel):
    """Single version entry for a versioned field"""
    database_id: str
    metadata_type: str  # 'database', 'table', 'column', 'term'
    table_name: Optional[str] = None  # Required for column metadata
    column_name: Optional[str] = None  # Required for column metadata  
    term_name: Optional[str] = None   # Required for term metadata
    field_name: str  # 'description', 'domain', 'encoding_mapping', etc.
    field_value: Any  # Actual field value
    source: str  # 'ddl_extract', 'manual', 'historical', 'llm_analysis'

# Source priority mapping (higher number = higher priority)
SOURCE_PRIORITY = {
    'ddl_extract': 4,
    'data_profiling': 4, 
    'manual': 3, 
    'historical': 2,
    'join_path_discovery': 2,  # Same priority as historical - automatically discovered relationships
    'llm_analysis': 1
}

# Fields that support versioning for each metadata type
VERSIONED_FIELDS = {
    'database': ['description', 'domain'],
    'table': ['description', 'table_role', 'row_definition'], 
    'column': ['encoding_mapping', 'description', 'pattern_description'],
    'term': ['definition', 'formula']
}


# ============================================================================
# Guidance Memory Types (for operational guidance from error patterns)
# ============================================================================

class GuidanceItem(BaseModel):
    """Single guidance insight item"""
    insight_id: str
    relevance_score: float
    
    # Core guidance content from insight.jsonl
    retrieval_key: Dict[str, Any]  # {nl_triggers: List[str], sql_risk_atoms: List[str]}
    guidance: Dict[str, Any]       # {intent, strategy_incorrect, strategy_correct, actionable_advice}
    
    # Example SQLs for understanding
    qualified_incorrect_sql: Optional[str] = None
    qualified_correct_sql: Optional[str] = None
    
    # Metadata
    source_question_ids: List[int] = []
    verification_success_count: Optional[int] = None
    verification_total_count: Optional[int] = None
    verification_success_rate: Optional[float] = None
    created_at: Optional[str] = None


class GuidanceResponse(BaseModel):
    """Response from guidance memory query"""
    items: List[GuidanceItem]
    query_time_ms: int
    total_insights_searched: int  # Total number of insights in the store
    total_sqls_processed: int     # Number of SQLs processed in this query

